% !TEX root = tnnls_depression_survey.tex

\ifx\allfiles\undefined
    \input{tnnls_prefix}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure*}[t]
%	\centering
%	\includegraphics[width=1.0\linewidth]{figures/network.pdf}
%	\caption{
%    Illustration of Gait Quality Aware Network.
%    The Encoder mainly consists of convolutional layers to extract the features from each silhouette separately.
%    FQBlock is taken to assess the quality of each silhouette where its weights are shared across the silhouettes but independent for different bins (annotated by different colors).
%    PQBlock operates on the set-level part representations and predicts a score to assess each part separately.
%    \emph{Set Pool} is taken to aggregate the features in a silhouette set.
%    $N$ denotes the number of silhouettes in a set,
%    $H$ and $W$ denote the height and width of the silhouette-level features,
%    $C$ and $\widehat{C}$ denote the channel dimension,
%    $S$ is the number of bins to horizontally slice the features which is equal to the number of parts.
%    Best viewed in color.
%	}
%	\label{fig_network}
%\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section{related work}
\section{background}

This section presents some basic knowledge in auxiliary depression diagnosis task including scales, datasets and assessment metrics.
Firstly, we introduce some scales of diagnosing depression which are used as label.
Secondly, we show some public datasets with different data modality.
Finally, we list some commonly used assessment metrics, which are important in evaluating the performance of methods.

\subsection{Depression Rating Scales}
%\subsection{Questionnaires}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}%[!htbp]\Large

\caption{Commonly used depression diagnosis scales}
\label{tab1}
\centering
%\renewcommand\arraystretch{1.5}
%\resizebox{0.9999\linewidth}{!}{
%\begin{threeparttable}

\begin{tabular}{c|c|c|c|c}
%\begin{tabular*}{\tblwidth}

\hline
%\textbf{Name}                                                                                                 & \multicolumn{1}{c|}{Items} & \multicolumn{1}{c|}{Scores} & \multicolumn{1}{c|}{Grading}                                                                                                                    & \multicolumn{1}{c}{Usage}     \\ \hline
\textbf{Name}                                                                                                 & \textbf{Items} & \textbf{Scores} & \textbf{Grading}                                                                                                                    & \textbf{Usage}     \\ \hline
\makecell[c]{Beck Depression Inventory (BDI)~\cite{1961An} }                                                       & 21                         & 0-63                        & \makecell[c]{0-9 minimal, 10-18 mild,\\ 19-29 moderate, 30-63 severe}                              & \multirow{12}{*}{self- rating}  \\ \cline{1-4}
%&\makecell[c]{0-9 minimal, 10-18 mild,\\ 19-29 moderate, 30-63 severe}                              & \multirow{12}{*}{self- rating}  \\ \cline{1-4}
\makecell[c]{Beck Depression Inventory-II (BDI-\uppercase\expandafter{\romannumeral2})~\cite{beck1975}}      & 13                         & 0-39 & \makecell[c]{0-4 minimal, 5-7 mild,\\ 8-15 moderate, 16-39 severe}                             &                                \\ \cline{1-4}
\makecell[c]{Self-rating depression scale (SDS)~\cite{SDS}  }                                          & 20                         & 20-80                       & \makecell[c]{20-53 minimal, 53-62 mild,\\ 63-72 moderate, 73-80 severe}                            &                                \\ \cline{1-4}
\makecell[c]{Patient Health Questionnaire (PHQ-9)~\cite{2013The} }                                            & 9                          & 0-27                        &\makecell[c]{0-5 minimal, 5-9 mild, \\ 10-14 moderate, 15-19 medium severe,\\ 20-27 severe}    &                                \\ \cline{1-4}
\makecell[c]{Center for Epidemiological Survey, Depression Scale (CES-D)~\cite{1977The}     }                    & 20                         & 0-60                        & \makecell[c]{0-15 minimal, 16-19 mild,\\ 20-25 moderate, 26-60 severe}                             &                                \\ \cline{1-4}
\makecell[c]{Geriatric Depression Scale (GDS)~\cite{brink1982screening}      }                                     & 30                         & 0-30                        & \makecell[c]{0-10 minimal, 11-20 mild,\\ 21-30 moderate}                                                  &                                \\ \hline
\makecell[c]{Hamilton Depression Scale (HAMD)~\cite{HAMD}    }                        & \makecell{17\\/21\\/\textbf{24} }                      &\makecell{0-34\\/0-42\\/\textbf{0-48} }         & \makecell[c]{0-8 minimal, 8-20 mild,\\ 20-35 moderate, 35-48 severe}                               & \multirow{8}{*}{others-rating} \\ \cline{1-4}
\makecell[c]{Montgomery-Asberg Depression Rating Scale (MADRS)~\cite{montgomery1979new}     }                    & 10                         & 0-60                        & \makecell[c]{0-12 minimal, 12-21 mild,\\ 22-29 moderate, 30-34 medium severe,\\ 35-60 severe} &                                \\ \cline{1-4}
\makecell[c]{International Classification of Diseases (ICD-10)~\cite{world1992icd}    }                            & -                          & -                           & \multirow{4.5}{*}{Clinical diagnosis criteria}                                                                                                                              &                                \\ \cline{1-3}
%\begin{tabular}[c]{@{}l@{}}International Classification of Diseases\\ (ICD-10)~\cite{world1992icd}\end{tabular}                                & -                          & -                           & \multirow{4.5}{*}{Clinical diagnosis criteria}                                                                                                                              &                                \\ \cline{1-3}
\makecell[c]{Diagnostic and Statistical Manual of Mental Disorders (DSM-IV)~\cite{segal2010diagnostic}   }       & -                          & -                           &                                                                                                                                                 &                                \\ \cline{1-3}
\makecell[c]{Chinese Classification and Diagnostic Criteria of Mental Disorders\\ (CCMD-3)~\cite{chen2002chinese}} & -                          & -                           &                                                                                                                                                 &                                \\ \hline
     
\end{tabular}
	\begin{tablenotes}
			\footnotesize
			\item There are three versions of the HAMD scale, 17, 21 and 24-item, and only the 24-item version is described here in detail.
			\item Clinical diagnosis criteria: Different criteria are listed for different numbers of symptoms, and doctors confirm the diagnosis of the condition based on the number of symptom matches and the duration of the patient's symptoms.			
		\end{tablenotes}
%\end{threeparttable}}
\end{table*}                             


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
As the most commonly used tools, a series of questionnaires capturing depressive symptoms had been developed and showed great success in psychiatric practice. The common depression test scales are shown in Table \ref{tab1}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[tbp]
	\centering	
	\label{fig_hard_case1}\includegraphics[width=1.0\linewidth]{figures/depression/BDI.png}		
	\caption{
	Short Form of the Beck Depression Inventory~\cite{beck1975}.
	}
	\label{BDI}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For each scale, there are several items with 3-4 options which rating to different scores. Subjects match one option they deem appropriate in each item and the different range of overall score is divided to different degree of depression. 
For example, the BDI-II scale is a 4-point scale which containing 21 items about sleep, appetite, mood, and suicidal thoughts, as shown in Fig \ref{BDI}.
Each item has 4 options and is rated ranging from 0 to 3. 
The highest overall score is 63, and higher scores indicate more severe depressive symptoms. 
Subjects will match one option of each item by the feelings in the past two weeks. 
After finishing the BDI-II scale, subject will get the degree of depression by overall score they matched.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The scales are divided into other-rating scales and self-rating scales by the way of testing scales.
%他评量表
For subjects, testing other-rating scales needs communication with psychiatrist, psychologist or other trained medical personnel at a professional place like hospital or clinic, which is more reliable but less convenient.
%自评量表
Self-rating scale like BDI-II is a kind of self-assessment under the Instruction manual, which can be easy complete in 5-10 minutes but not quite reliable.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The scale is tried to test the emotions of subjects, because negative emotions are the main performance of depressed people. 
However, people with negative emotions are not the same as with depression.
Measuring depression on a scale alone has limitations, so that physiological electrical signals or brain images from subjects for auxiliary depression diagnosis during professional diagnosis.
In recent years, some research showed that abnormal behavioral signals like facial expressions, voice and gait can reflect mental disease, which is more easily to observe compared with physiological electrical signals or brain images.
For example, depressed people have dull facial expressions, rarely make eye contact, use phrases with a flat tone when speaking, and walk slowly. By analyzing the abnormal behavioral signals can be well in auxiliary diagnosing depression.


\subsection{Datasets}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%The world around us involves many modes, we see objects, hear sounds, feel textures, smell smells, and so on. Most people associate the word modality with sensory modality, which represents the main channel of our communication and sensation, such as vision, hearing, etc.
This section introduces some public datasets as shown in Table \ref{tab2}, including the name, information of subject and data mode. Due to privacy issues, only several of the modal data has public dataset.
Therefore, most researchers use the data collected by themselves for analysis.

The Reddit Self-reported Depression Diagnosis (RSDD) dataset consists of Reddit posts for 9,210 users who have claimed to have been diagnosed with depression ("diagnosed users") and 107,274 matched control users, which is a large-scale general forum dataset. The data is in JSON format, and each row is an array representing a user. The label field includes the user’s label (control or depression), and the posts field contains timestamp and untokenized pairs.

The eRsik dataset consists of text examples collected from messages of 887 Reddit users. The main idea of the task is to classify users into risk case of depression and non-risk case.

Multi-modal Open Dataset for Mental-disorder Analysis (MODMA) consists data mainly from clinically depressed patients and matching normal controls, which is a multi-modal open dataset for mental-disorder analysis. All patients in MODMA were carefully diagnosed and selected by professional psychiatrists in hospitals. EEG and speech recording data are made publicly available in MODMA. The EEG signals were recorded as both in resting state and under stimulation, and EEG dataset includes not only data collected using traditional 128-electrodes mounted elastic cap, but also a novel wearable 3-electrode EEG collector for pervasive applications. The speech data were recorded as during interviewing, reading and picture description.

Audio-Visual Emotion Challenge (AVEC) is an expression recognition challenge held every year since 2011, which is recognized as the top international competition in the field of emotional computing. AVEC2013 began to introduce the task of depression recognition, which considers the analysis of depression based on auditory vision as a classification problem or regression problem.

%%%%%%%%AVEC%%%%%%%%%%%%%%%%%%%

Audio-Visual Depression Corpus (AViD-Corpus) contains 340 video clips of subjects performing a Human-Computer Interaction task while being recorded by a webcam and a microphone. The speakers were recorded between one and four times, with a period of two weeks between the measurements. This data was used for the AVEC2013 and AVEC2014 Challenge, and AVEC2014 uses a subset of the AVEC 2013 audio-visual depression corpus. 

Distress Analysis Interview Corpus – Wizard of Oz (DAIC-WOZ) contains clinical interviews designed to support the diagnosis of psychological distress conditions such as anxiety, depression, and post-traumatic stress disorder. Data collected include audio and video recordings and extensive questionnaire responses~\cite{gratch2014distress}. This data was used for the AVEC2016 and AVEC2017 Challenge.

Extended DAIC Database(E-DAIC) is the extended version of DAIC-WOZ database for depression and PTSD assessment, developed by ICT~\cite{gratch2014distress}. This data was used for the AVEC2019 Challenge.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Wyss Institute Biomarkers for Depression(WIBD)

%The EATD-Corpus is a dataset consist of audio and text files of 162 volunteers who received counseling.
Emotional Audio-Textual Depression Corpus (EATD-Corpus) contains audios and extracted transcripts of responses from 162 depressed and non-depressed volunteers. EATD-Corpus is the first and only public depression dataset that includes audio and text data in Chinese.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%There are also many announcements of dataset chants used in ADD, as shown in Table \ref{tab2}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}
\centering
\caption{Commonly used datasets}
\label{tab2}
\setlength\tabcolsep{3mm}{
%\renewcommand\arraystretch{1.5}
%\resizebox{0.9999\linewidth}{!}{
%\begin{threeparttable}

\begin{tabular}{c|c|c|c|c}

     %\begin{table}[]
	%\begin{tabular}{l|l|l|l}
	%\begin{tabularx}{15cm}{X|X|X|X}
	%\begin{tabularx}{c|c|c|c}
	\hline
\textbf{ }      &\textbf{Dataset}                    & \textbf{Subjects (D+H)} & \textbf{Type}                & \textbf{Task}                     \\
\hline
%Michalak et al.~\cite{2009Embodiment}                                                      &                                                                                                                & 14 MDD                                                                                                              & Depression          & \multirow{10}{*}{Gait}      \\
%Yuan et al. ~\cite{yuan2019Depression}                                                         & \begin{tabular}[c]{@{}l@{}}Healthy people and \\depressed patients                                                                         \end{tabular} & \begin{tabular}[c]{@{}l@{}}101 \\ (54:47)\end{tabular}                                                         & Depression          &                            \\
%Tamar et al.~\cite{Tamar2012Depressive}                                                          & Elderly                                                                                                        & 610                                                                                                                 & Depression          &                            \\
%Briggs et al. ~\cite{2019Do}                                                        & Elderly                                                                                                        & 3615                                                                                                                & Depression          &                            \\
%Fang et al. ~\cite{fang2019Depression}                                                          & College Students                                                                                               & 3669                                                                                                                & Depression          &                            \\
%Zhao et al.  ~\cite{2019See}                                                         & \begin{tabular}[c]{@{}l@{}}College Students    \\ (University of Chinese\\ Academy of   Sciences)\end{tabular} & 179                                                                                                                 & Anxiety +Depression &                            \\
%\hline
\multirow{8}{*}{Public}        &RSDD  ~\cite{yates2017depression}                    &116484 (9210+107274)                                                                                                    
& Depression          & \multirow{2.2}{*}{Text (Social Network) }          \\
 &eRisk ~\cite{Stankevich2018FeatureEF}               
&887          & Depression          &   \\
\cline{2-5}
%ChunkeJing et al.~\cite{ChunkeJing2019Different}                                                        & volunteers                                                                                                     & 88                                                                                                                  & Anxiety +Depression & Speech+Gait                \\
%\hline
 &MODMA ~\cite{2020MODMA}                                                       & \begin{tabular}[c]{@{}l@{}}53  (24/29) \emph{EEG}    \\ 52  (23+29) \emph{Audio}\end{tabular} & Mental-disorder          & EEG+ Audio                 \\
\cline{2-5}
 &AVEC2013/2014 \& AViD-Corpus~\cite{valstar2014avec}                                                             & \begin{tabular}[c]{@{}l@{}}100  (46+54)\end{tabular}                                                         & Depression          & \multirow{3.5}{*}{Audio+ Facial expressions} \\
 &AVEC2016/2017 \& DAIC-WOZ~\cite{nasir2016multimodal}                                                         & \begin{tabular}[c]{@{}l@{}}193 (60+133)\end{tabular}                                                        & Depression          &                                              \\
 &AVEC2019 \& E-DAIC ~\cite{ringeval2019avec}                                                                                                                                                                       &275                                                                                                                    & Depression          &
\\
%WIBD~\cite{2019Tracking}                                                              &                                                                                                                & \begin{tabular}[c]{@{}l@{}}18    \\ (12/6)\end{tabular}                                                           & Depression          &                                             \\
%Pittsburgh ~\cite{2017Dynamic}                                                      &                                                                                                                & \begin{tabular}[c]{@{}l@{}}130    \\ (93/37)\end{tabular}                                                         & Depression          &                                            
%\\    
\cline{2-5}
 &EATD-Corpus ~\cite{2022Automatic}                                                            & \begin{tabular}[c]{@{}l@{}}162  (30+132)\end{tabular}                                                        & Depression          &Audio+ Text                                \\
\hline          
\multirow{8}{*}{Private}        &  Song et al. ~\cite {2015Automatic}                    &138 (108+30)                                                                                                    
& Depression          & \multirow{2.2}{*}{Brain imaging (fNIRS)}          \\
 & Ma et al.~\cite{2020DISTINGUISHING }                    &84 (36D+48B)
& Depression + bipolar disorder       &          \\
\cline{2-5}
                    &  Acharya et al.\cite{acharya2015novel}                    &30 (15+15)                                                                                                    
& Depression          & \multirow{2.2}{*}{Electrophysiological signals (EEG)}          \\
 &wan et al.\cite{wan2020hybrideegnet}                   &35 (23+12)
& Depression       &          \\
\cline{2-5}
                    & Zhang et al.\cite{zhang2011new}           &20 (10+10)                                                                                                    
& Depression          & \multirow{2.2}{*}{Electrophysiological signals (HRV)}          \\
 &Byuna et al.\cite{byun2019detection}                   &72 (31+41)
& Depression       &          \\
\cline{2-5}
                    &  Yuan et al. ~\cite{yuan2019Depression}                    &101 (54+47)                                                                                                    
& Depression          & \multirow{2.2}{*}{Gait}          \\
 &Zhao et al.  ~\cite{2019See}                  &179
& Depression + Anxiety       &          \\
\cline{2-5}
	\hline              
	%\end{tabular}
	\end{tabular}}
	%\end{table}
	%\end{threeparttable}}
	\begin{tablenotes}
			\footnotesize
			\item B means bipolar disorder patients.
		\end{tablenotes}

\end{table*} 

\ifx\allfiles\undefined
\input{tnnls_suffix}
\fi
%{\shortstack{Speech+ Facial\\ expressions}}

\subsection{Metrics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Depression by scale is classified into different levels according to the score, such as minimal, mild, moderate, and severe. Different scales have different ways of classification. 
In many studies, depression detection was seen as a binary classification problem. Subject with the minimal degree of the scale were labeled to have non-depressed and others were labeled to have depressed.
And the experimental evaluation methods were some common classification metrics such as precision, accuracy, recall, F1-score, specificity, sensitivity and Area Under the Curve (AUC), and accuracy is the most frequently used of these metrics.

Some studies used regression analysis to predict the degree of depression according to the score of scale, and the experimental evaluation methods were some common regression metrics as: mean absolute error (MAE) and root mean squared error (RMSE).

\subsubsection{Classification indicators}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Confusion metrics is the basic of classification metrics. And confusion metrics can be split to 4 parts: True Positive (TP), False Positive (FP), False Negative (FN) and True Negative (TN). TP means a positive sample and predicted as positive. False Positive FP means a positive sample but predicted as negative. False Negative FN means a negative sample but predicted as positive. True Negative TN means a negative sample and predicted as negative. Therefore, the total positive samples can be calculated as $TP+FP$, and the total negative samples can be calculated as $FN+TN$. The overall of confusion metrics is shown in Fig \ref{metric}.

\begin{figure}[tbp]
	\centering	
	\label{fig_hard_case1}\includegraphics[width=1.0\linewidth]{figures/depression/metric3.png}		
	\caption{
	Confusion Matrix: each row represents the forecast category, and the total number of each row represents the number of data predicted for that category. Each column represents the real category of data, and the total data in each column represents the number of data instances of this category.
	}
	\label{metric}
\end{figure}


\emph{Precision} reflects the ability of the model to correctly predict positive samples, it calculates how many positive samples are predict as \emph{positive}. The calculation formula as follows:

\begin{equation}
 Precision =\frac{TP}{TP+FP}
\end{equation}


\emph{Accuracy} reflects the ability of the model to correctly predict the overall sample, it calculates how many positive samples are predict as \emph{positive} and negative samples as \emph{negative}. The calculation formula as follows:

\begin{equation}
Accuracy =\frac{TP+TN}{TP+FN+FP+TN}=\frac{TP+TN}{P+N}
\end{equation}


\emph{Recall} reflects the ability of the model to correctly predict the full degree of positive samples, it  calculates the proportion of positive samples predicted as \emph{positive} to the total positive samples. The calculation formula as follows:

\begin{equation}
Recall =\frac{TP}{TP+FN}=\frac{TP}{P}
\end{equation}


\emph{F1-score} is a statistical measure of the accuracy of model. It defined as the harmonic mean of precision and recall. The formula as follows:

\begin{equation}
F1-score=\frac{2 \times  Precision  \times   Recall }{ Precision + Recall }
\end{equation}


\emph{Specificity} reflects the ability of the model to correctly predict the full extent of negative samples, it  calculates the proportion of negative samples predicted to be \emph{negative} to the total negative samples. The calculation formula as follows:

\begin{equation}
Specificity =\frac{TN}{FP+TN}=\frac{TN}{N}
\end{equation}


\emph{Sensitivity} reflects the ability of the model to correctly predict the full extent of positive samples, it  calculates the proportion of positive samples predicted to be \emph{positive} to the total positive samples. The calculation formula as follows:

\begin{equation}
 Sensitivity =\frac{TP}{TP+FN}=\frac{TP}{P}
\end{equation}


\begin{figure}[tbp]
	\centering	
	\label{fig_hard_case1}\includegraphics[width=1.0\linewidth]{figures/depression/AUC2.png}		
	\caption{
	ROC curve is obtained based on confusion matrix. Its abscissa is FPR, and ordinate is TPR. Draw the coordinates of the same model (FPR, TPR) in ROC space, and it becomes the ROC curve. 
	AUC is defined as the area under the ROC curve. 
	}
	\label{AUC}
\end{figure}

\emph{ROC} represents a probability graph to show the performance of a classification model at different threshold levels. 
The curve is plotted between two parameters, which are: True Positive Rate(TPR) and False Positive Rate (FPR).
TPR is a synonym for Recall, which can be calculated as:

\begin{equation}
TPR =\frac{TP}{TP+FN}
\end{equation}

FPR can be calculated as:

\begin{equation}
FPR =\frac{FP}{FP+TN}
\end{equation}

\emph{AUC} is known for Area Under the ROC curve. AUC calculates the two-dimensional area under the entire ROC curve ranging from (0,0) to (1,1), as shown in Fig \ref{AUC}.
In the ROC curve, AUC computes the performance of the binary classifier across different thresholds and provides an aggregate measure. The value of AUC ranges from 0 to 1, which means an excellent model will have AUC near 1.

%The area covered by the ROC curve downward is the AUC value, and since the ROC curve is generally above the line $y=x$, the value of AUC ranges between 0.5 and 1. The closer the AUC is to 1.0, the higher the authenticity of the detection method; when it is equal to 0.5, it is the lowest authenticity and has no application value.

%As a numerical value, AUC will more clearly explain the effect of the classifier than ROC curve.

\subsubsection{Regression indicators}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
MAE and RMSE are often used to quantify how well a model fits a dataset.

\emph{MAE} reflects the mean absolute difference between the predicted values and the actual values in a dataset. The lower the MAE, the better a model fits a dataset. The calculation formula as follows:

\begin{equation}
MAE= \frac{1}{n} \sum_{i=0}^{n}\left | y_{i} -\breve{y}_{i}\right |
\end{equation}

Where $y_{i}$ is the observed value for the $i^{th}$ observation, $\breve{y}_{i}$ is the predicted value for the $i^{th}$ observation, and $n$ is the sample size.


\emph{RMSE} reflects the square root of the average squared difference between the predicted values and the actual values in a dataset. The lower the RMSE, the better a model fits a dataset. The calculation formula as follows:

\begin{equation}
RMSE=\sqrt{\frac{1}{n} \sum_{i=0}^{n}\left (y_{i} -\breve{y}_{i}\right )^{2} }  
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Many studies have shown that depressed and healthy people are very different in many aspects, such as brain imaging, electrophysiological signals, audiovisual data, text, and other multi-modal data. By analyzing the abnormal performance, these data can auxilia in the depression diagnose.


\begin{figure}[tbp]
	\centering	
	\label{fig_hard_case1}\includegraphics[width=1.0\linewidth]{figures/depression/method.png}		
	\caption{
	classification method. 
	}
	\label{method}
\end{figure}

\subsection{Methods}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Although various methods have been proposed to auxiliary depression diagnosis base on different multimodal data, the process of methods is similar, as shown in  Fig \ref{method}.

(1)\emph{Pre-processing:} Most of the raw data have a lot of noises from capture device and environment.
For example, electrophysiological signal has baseline drift, power-line interference and Electromyography signal all affected by the equipment and human body.
Similarly, other data modality also has interference caused by the acquisition equipment and environment.
So, it is necessary to preprocess the raw data and use appropriate methods to remove different noises.
Such as setting frequency intervals to remove power-line and Electromyography interference, and using filters to eliminate baseline drift.

(2)\emph{Feature extraction:} Feature extraction means to the process of transforming raw data into numerical features that can be processed while preserving the information. 
Feature extraction includes manual or automatic.
Manual feature extraction requires researchers to manually extract features based on the characteristics of data and task. 
In many situations, having a good understanding of the task can help make informed decisions as to which features could be useful.
Automated feature extraction uses specialized algorithms to extract features automatically from data without the need for human intervention, such as deep learning methods (CNN, RNN, DNN...).

In some cases, it is necessary to reduce the dimension of extracted features, including feature selection and feature fusion, to lessen the amount of calculation.

(2)\emph{Classification:} Auxiliary depression diagnostic methods based on different modes are divided into traditional machine learning classifiers such as Support Vector Machine (SVM), Random Forests (RF), Logistic Regression (LR), and deep learning methods such as Convolutional Neural Networks (CNN), Deep Neural Networks (DNN), Recurrent Neural Network (RNN).

%%%%%%%%%%% differernt data modality

Although the processes are similar, the auxiliary depression diagnostic methods based on various data modalities are not comparable because the data types, extraction features and classification algorithms are all different.
